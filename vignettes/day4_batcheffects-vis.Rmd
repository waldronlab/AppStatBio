---
title: "Applied Statistics for High-throughput Biology: Session 4"
output: slidy_presentation
author: "Levi Waldron"
vignette: >
  %\VignetteIndexEntry{Applied Statistics for High-throughput Biology: Session 4}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  cache = TRUE,
  collapse = TRUE,
  comment = "#>"
)
library(AppStatBio)
```

## Outline

- [Exploratory data analysis](https://genomicsclass.github.io/book/pages/exploratory_data_analysis.html) (Chapter 2)
    - Quantile Quantile (QQ)-plots
    - Boxplots
    - Scatterplots
    - Volcano plots
    - p-value histograms
    - MA plots
    - heatmaps
- [Batch effects](http://genomicsclass.github.io/book/pages/intro_to_batch_effects.html) (Chapter 10)

# Exploratory data analysis

## Introduction

> “The greatest value of a picture is when it forces us to notice what we never expected to see.” - John W. Tukey

- Discover biases, systematic errors and unexpected variability in data.
- Graphical approach to detecting these issues. Represents a first step in data analysis and guides hypothesis testing.
- EDA helps us check the assumptions of our statistical tests.
- Opportunities for discovery are often in the outliers.

## Quantile Quantile Plots

- **Why use them?** A primary tool for checking if our data follows a theoretical distribution.`
- Quantiles divide a distribution into equally sized bins (e.g., 100 bins for percentiles).
- We plot the quantiles from our data against the theoretical quantiles of a distribution (e.g., the normal distribution).
- If our data perfectly matches the theoretical distribution, the points will form a straight line ($y=x$). Deviations from the line indicate our data does not fit that distribution.

## Example: Quantile Quantile Plots

```{r qq1, echo=FALSE, fig.width=8}
suppressPackageStartupMessages(library(UsingR))
suppressPackageStartupMessages(library(rafalib))
# height qq plot
x <- father.son$fheight
ps <- (seq(0, 99) + 0.5) / 100
qs <- quantile(x, ps)
normalqs <- qnorm(ps, mean(x), popsd(x))
par(mfrow = c(1, 3))
plot(normalqs,
     qs,
     xlab = "Normal Percentiles",
     ylab = "Height Percentiles",
     main = "Height Q-Q Plot")
abline(0, 1)
# t-distributed for 12 df
x <- rt(1000, 12)
qqnorm(x,
       xlab = "t quantiles",
       main = "T Quantiles (df=12) Q-Q Plot",
       ylim = c(-6, 6))
qqline(x)
# t-distributed for 3 df
x <- rt(1000, 3)
qqnorm(x,
       xlab = "t quantiles",
       main = "T Quantiles (df=3) Q-Q Plot",
       ylim = c(-6, 6))
qqline(x)
```

## Boxplots: About

- **Why use them?** Boxplots excel at showing the distribution of data, especially when it is not normally distributed (e.g., highly skewed data like income).
- They provide a simple, easy-to-interpret summary of the data's range, center, and spread, while clearly highlighting outliers.
- Their greatest advantage comes from placing them side-by-side to compare distributions across multiple groups at once.

## Boxplots: Example

```{r bp1, echo=FALSE, fig.width=8, fig.height=4}
par(mfrow=c(1, 3))
hist(exec.pay, main = "CEO Compensation")
qqnorm(exec.pay, main = "CEO Compensation")
boxplot(exec.pay, ylab="10,000s of dollars", ylim=c(0,400), main = "CEO Compensation")
```
<center>
Three different views of a continuous variable. The boxplot clearly shows the skew and outliers.
</center>

## Scatterplots And Correlation: About

- For two continuous variables, a scatter plot graphically shows the relationship, while correlation provides a single number to summarize its strength and direction.
- Quick and easy with `plot()` and `cor()`.

## Scatterplots And Correlation: Example

```{r cor1, echo=FALSE, fig.width=8, fig.height=4}
par(mfrow = c(1, 3))
plot(
  father.son$fheight,
  father.son$sheight,
  xlab = "Father's height in inches",
  ylab = "Son's height in inches",
  main = paste("correlation =", signif(
    cor(father.son$fheight, father.son$sheight), 2
  ))
)
plot(
  cars$speed,
  cars$dist,
  xlab = "Speed",
  ylab = "Stopping Distance",
  main = paste("correlation =", signif(cor(
    cars$speed, cars$dist
  ), 2))
)
plot(
  faithful$eruptions,
  faithful$waiting,
  xlab = "Eruption Duration",
  ylab = "Waiting Time",
  main = paste("correlation =", signif(
    cor(faithful$eruptions, faithful$waiting), 2
  ))
)
```

## Exploratory data analysis in high dimensions


```{r eda1}
library(GSE5859Subset)
data(GSE5859Subset) ##this loads three tables
class(geneExpression)
dim(geneExpression)
class(sampleInfo)
dim(sampleInfo)
head(sampleInfo)
```

## Volcano plots: Setup

T-test for every row (gene) of gene expression matrix:
```{r vp1, message=FALSE}
library(genefilter)
g <- factor(sampleInfo$group)
system.time(results <- rowttests(geneExpression, g))
pvals <- results$p.value
```

Note that these 8,793 tests are done in about 0.01s

## Volcano plots: Example

```{r vp2, echo = FALSE, fig.height=5, fig.width=5}
par(mar = c(4, 4, 0, 0))
plot(results$dm,
     -log10(results$p.value),
     xlab = "Effect size (difference in group means)",
     ylab = "- log (base 10) p-values")
abline(h = -log10(0.05 / nrow(geneExpression)), col = "red")
legend("bottomright",
       lty = 1,
       col = "red",
       legend = "Bonferroni = 0.05")
```

## Volcano plots: Summary

- A volcano plot lets us visualize both the **statistical significance** (p-value) and **biological significance** (effect size or fold change) at the same time for thousands of genes.
- **Top-right/left corners:** Genes with large effect sizes and high statistical significance. These are often the most interesting candidates.
- **Top-center:** Genes that are statistically significant but have a small effect size.
- **Bottom:** Genes that are not statistically significant, regardless of their effect size.
- Can color points by significance threshold. Check for asymmetry, which might indicate biases.

## P-value histograms: Setup

- If all null hypotheses are true (i.e., no genes are truly differentially expressed), we expect a **flat histogram** of p-values, where every p-value from 0 to 1 is equally likely.

```{r pvalhist1}
m <- nrow(geneExpression)
n <- ncol(geneExpression)
set.seed(1)
randomData <- matrix(rnorm(n * m), m, n)
nullpvals <- rowttests(randomData, g)$p.value
```

## P-value histograms: Example

```{r pvalhist2, echo=FALSE, fig.height=3}
par(mfrow = c(1, 2))
hist(pvals, ylim = c(0, 1400))
hist(nullpvals, ylim = c(0, 1400))
```

## P-value histograms: Example 2 (permutation)

Note that permuting these data doesn't produce an ideal null p-value histogram due to batch effects:

```{r pvalhist3, fig.height=3}
permg <- sample(g)
permresults <- rowttests(geneExpression, permg)
hist(permresults$p.value)
```

## P-value histograms: Summary

- Give a quick look at the overall results of a high-throughput experiment. A spike near zero suggests the presence of differentially expressed genes.
- A non-uniform histogram for permuted data is a red flag, suggesting non-independence between samples, often due to hidden batch effects.

## MA plot

- **Why use it?** An MA plot is a clever transformation of a scatter plot, designed to better visualize differences between two samples (or one sample and a reference). It's just a scatterplot rotated 45$^o$.
- The rotation helps us see systematic biases. The 'A' (Average) on the x-axis represents overall signal intensity, and the 'M' (Minus, or log-ratio) on the y-axis represents the fold change. This makes it much easier to see if the fold change is dependent on gene intensity.

```{r pvalhist4, fig.height=3}
rafalib::mypar(1, 2)
pseudo <- apply(geneExpression, 1, median)
plot(geneExpression[, 1], pseudo) # Standard scatter plot
plot((geneExpression[, 1] + pseudo) / 2, (geneExpression[, 1] - pseudo)) # MA plot
```

## MA plot: Summary

- Useful for quality control of high-dimensional data.
- In an ideal MA plot, the cloud of points is centered on y=0 with no trend.
- `affyPLM::MAplots` creates better MA plots, adding a smoothing line to highlight departures from the horizontal.

## Heatmaps

* Detailed representation of a high-dimensional dataset. The `ComplexHeatmap` package is the best as of 2025.
* **Important Note:** Before plotting, we usually **scale** the data for each gene. This ensures the color pattern is driven by relative expression changes, not by a few highly expressed genes dominating the color scale.

```{r ma1, fig.width=12, echo=FALSE}
suppressPackageStartupMessages(library(ComplexHeatmap))
keep <- rank(apply(geneExpression, 1, var)) <= 100
ge <- geneExpression[keep, ]
ge <- t(scale(t(ge))) # Scale genes across samples
rownames(ge) <- NULL; colnames(ge) <- NULL
chr <- sub("chr", "", geneAnnotation$CHR)
chr[is.na(chr)] <- "Un"
chr <- factor(chr, levels = c(1:22, "Un", "X", "Y"))
chrcols <- list(chromosome = c(colorRampPalette(c("lightgrey", "black"))(22), "white", "pink", "blue"))
names(chrcols[["chromosome"]]) <- c(1:22, "Un", "X", "Y")
row_ha <- rowAnnotation(chromosome = chr[keep], col = chrcols, na_col = "white")
column_ha <- HeatmapAnnotation(ethnicity = sampleInfo$ethnicity, group = factor(sampleInfo$group),
                               col = list(ethnicity = c("ASN"="lightgrey", "CEU"="darkgrey"),
                                          group = c("0" = "brown", "1" = "blue")))
Heatmap(ge, use_raster = FALSE, top_annotation = column_ha, right_annotation = row_ha)
```

## Heatmaps: Summary

- Clustering becomes slow for thousands of rows but is great for visualizing co-expressed genes and sample groups.

## Colors

- Palettes: **sequential** (gradient), **diverging** (two directions from a center), **qualitative** (categorical).
- Keep color blindness in mind (10% of men). `RColorBrewer` has colorblind-friendly options.

## Plots To Avoid

> "Pie charts are a very bad way of displaying information." - R Help

- **Avoid pie charts and doughnut charts.** Humans are much better at judging length and position than angles and areas. A simple bar chart is almost always a better, clearer alternative.
- **Avoid pseudo 3D plots.** They distort the data and make comparisons difficult.
- Use color judiciously to highlight, not to decorate.

# Batch effects

## Pervasiveness of batch Effects

- Pervasive in genomics and have caused high-profile retractions.
- You can't get rid of them, but you can design your experiment to manage them.
- **The Golden Rule:** Make sure batch is not confounded with your variable of interest.
- Consider this **nightmare scenario**:

> * **Batch 1:** All your "Control" samples, processed on Monday.
> * **Batch 2:** All your "Treatment" samples, processed on Tuesday.
>
> If you find a difference, is it due to the treatment or the processing day? It's **impossible to know**.

Prevent such "confounding" through **blocking** and **randomization** during experimental design.

## Blocking and Randomization

* _Randomization_ is the process of randomly assigning participants or experimental units to different treatments or batches.
   - Randomization is the only way to guarantee there can be no systematic relationship between treatment and batch, or between study subject and treatment
* _Blocking_ is the process of grouping similar experimental units together to control for known sources of variability (e.g., time, technician, reagent lot).
   - For example, if you have multiple technicians, you can block by technician to ensure each treatment is applied by each technician.
   - This helps reduce variability and improve the accuracy of your results.
   - Only works for known sources of variability

## The batch effects impact clustering

```{r clust1}
# Data from a real study where date of processing was confounded with ethnicity
library(Biobase)
library(genefilter)
library(GSE5859)
data(GSE5859)
geneExpression = exprs(e)
sampleInfo = pData(e)
year <-  as.integer(format(sampleInfo$date, "%y")) - min(as.integer(format(sampleInfo$date, "%y")))
hcclass <- cutree(hclust(as.dist(1 - cor(geneExpression))), k = 5)
table(hcclass, year) # Clustering is driven by year of processing, not biology
```

## Approaches to correcting for batch effects

Methods can be categorized by their approach and data type:

* **Simple Rescaling (e.g., `batchelor::rescaleBatches()`):**
    * Rescales batches to have the same mean/variance.
    * Good for single-cell data because it maintains sparsity (zeros stay zeros).

* **For Known Batches (Bulk RNA-seq):**
    * **`limma::removeBatchEffect()`** or **`sva::ComBat()`**: Use a linear model to regress out the effect of known batch variables (e.g., processing date, sequencing machine). Assumes cell type composition is similar across batches.

* **For Unknown Batches (Bulk RNA-seq):**
    * **`sva::sva()`**: Identifies and creates "surrogate variables" that capture hidden sources of variation. Excellent when you don't know the exact source of the batch effect but the p-value histogram looks problematic.

* **For Single-Cell Data Integration:**
    * **`batchelor::fastMNN()`**: Finds Mutual Nearest Neighbors (MNNs) between batches to align them. Powerful for single-cell RNA-seq because it does **not** assume the same composition of cells across batches.

## Batch Effects - summary

- Batch effects can ONLY be corrected if they are not confounded with your variable of interest.
- **Randomization is your best defense.**
- Always record info that might become a batch effect (date, technician, reagent lot, etc.).
- Include control samples in each batch.

## Links

-   A built [html](https://waldronlab.io/AppStatBio/articles/day4_batcheffects-vis.html)
    version of this lecture is available.
-   The [source](https://github.com/waldronlab/AppStatBio/blob/main/vignettes/day4_batcheffects-vis.Rmd) R Markdown is
     available from Github.

