---
title: "Random Variables Exercises"
author: "Levi Waldron"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

For these exercises, we will be using the following dataset:

```{r}
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/femaleControlsPopulation.csv"
x <- read.csv(url)
x <- unlist(x)
```

Here x represents the weights for the entire population.

# Question 1

What is the average of these weights?
```{r}
mean(x)
```


# Question 2

After setting the seed at 1 (`set.seed(1)`) take a random sample of size 5. What is the absolute value (use abs) of the difference between the average of the sample and the average of all the values?

```{r}
set.seed(1)
sam <- sample(x, 5)
abs(mean(sam) - mean(x))
```

# Question 3

After setting the seed at 5, set.seed(5) take a random sample of size 5. What is the absolute value of the difference between the average of the sample and the average of all the values?

```{r}
set.seed(5)
sam <- sample(x, 5)
abs(mean(sam) - mean(x))
```

# Question 4

Why are the answers from 2 and 3 different?

    * A) Because we made a coding mistake.
    * B) Because the average of the x is random.
    * C) Because the average of the samples is a random variable.
    * D) All of the above.

# Question 5 

Set the seed at 1, then using a for-loop take a random sample of 5 mice 1,000 times. Save these averages. What percent of these 1,000 averages are more than 1 ounce away from the average of x ?

```{r}
set.seed(1)
FUN <- function(size=5){
    sam <- sample(x, size)
    output <- mean(sam) - mean(x)
    return(output)
}
res <- replicate(n=1000, expr=FUN())
summary(abs(res) > 1)
```

# Question 6

We are now going to increase the number of times we redo the sample from 1,000 to 10,000. Set the seed at 1, then using a for-loop take a random sample of 5 mice 10,000 times. Save these averages. What percent of these 10,000 averages are more than 1 ounce away from the average of x ?

```{r}
res2 <- replicate(n=10000, expr=FUN())
summary(abs(res2) > 1)
```

# Question 7

Note that the answers to 4 and 5 barely changed. This is expected. The way we think about the random value distributions is as the distribution of the list of values obtained if we repeated the experiment an infinite number of times. On a computer, we can’t perform an infinite number of iterations so instead, for our examples, we consider 1,000 to be large enough, thus 10,000 is as well. Now if instead we change the sample size, then we change the random variable and thus its distribution.

Set the seed at 1, then using a for-loop take a random sample of 50 mice 1,000 times. Save these averages. What percent of these 1,000 averages are more than 1 ounce away from the average of x ?

```{r}
set.seed(1)
res3 <- replicate(n=1000, expr=FUN(size=50))
summary(abs(res3) > 1)
```

```{r}
par(mfrow=c(1, 2))
hist(res, xlim=c(-6, 6), main="size=5")
abline(v=c(-1, 1), col="red")
hist(res3, xlim=c(-6, 6), main="size=50")
abline(v=c(-1, 1), col="red")
```

SE = sd / sqrt(size)

```{r}
sd(x)
sd(x) / sqrt(5)
sd(res2)
sd(x) / sqrt(50)
sd(res3)
```

# Question 8

Use a histogram to “look” at the distribution of averages we get with a sample size of 5 and a sample size of 50. How would you say they differ?

    A) They are actually the same.
    B) They both look roughly normal, but with a sample size of 50 the spread is smaller.
    C) They both look roughly normal, but with a sample size of 50 the spread is larger.
    D) The second distribution does not look normal at all.

# Question 9

For the last set of averages, the ones obtained from a sample size of 50, what percent are between 23 and 25?

```{r}
summary(23 < (res3 + mean(x)) & (res3 + mean(x))  < 25)
```

# Question 10

Now ask the same question of a normal distribution with average 23.9 and standard deviation 0.43.

```{r}
res4 <- rnorm(n=1000, mean=23.9, sd=0.43)
summary(23 < res4 & res4 < 25)
```


The answer to 9 and 10 were very similar. This is because we can approximate the distribution of the sample average with a normal distribution. We will learn more about the reason for this next.

