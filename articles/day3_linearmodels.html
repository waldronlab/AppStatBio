<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Applied Statistics for High-throughput Biology: Session 3 • AppStatBio</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.4.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Applied Statistics for High-throughput Biology: Session 3">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">AppStatBio</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.0.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/day1_intro.html">Applied Statistics for High-throughput Biology: Session 1</a></li>
    <li><a class="dropdown-item" href="../articles/day2_unsupervised.html">Applied Statistics for High-throughput Biology: Session 2</a></li>
    <li><a class="dropdown-item" href="../articles/day3_linearmodels.html">Applied Statistics for High-throughput Biology: Session 3</a></li>
    <li><a class="dropdown-item" href="../articles/day4_batcheffects-vis.html">Applied Statistics for High-throughput Biology: Session 4</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/waldronlab/AppStatBio/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Applied Statistics for High-throughput Biology: Session 3</h1>
                        <h4 data-toc-skip class="author">Levi
Waldron</h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/waldronlab/AppStatBio/blob/main/vignettes/day3_linearmodels.Rmd" class="external-link"><code>vignettes/day3_linearmodels.Rmd</code></a></small>
      <div class="d-none name"><code>day3_linearmodels.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="outline">Outline<a class="anchor" aria-label="anchor" href="#outline"></a>
</h2>
<ul>
<li>Multiple linear regression
<ul>
<li>Continuous and categorical predictors</li>
<li>Interactions</li>
</ul>
</li>
<li>Model formulae</li>
<li>Generalized Linear Models
<ul>
<li>Linear, logistic, log-Linear links</li>
<li>Poisson, Negative Binomial error distributions</li>
</ul>
</li>
<li>Multiple Hypothesis Testing</li>
</ul>
</div>
<div class="section level2">
<h2 id="textbook-sources">Textbook sources<a class="anchor" aria-label="anchor" href="#textbook-sources"></a>
</h2>
<ul>
<li>
<a href="http://genomicsclass.github.io/book/" class="external-link">Biomedical Data
Science</a>
<ul>
<li>Chapter 5: Linear models</li>
<li>Chapter 6: Inference for high-dimensional data</li>
</ul>
</li>
<li>
<a href="https://www.huber.embl.de/msmb/06-chap.html" class="external-link">Modern
Statistics for Modern Biology</a>
<ul>
<li>Chapter 6: Testing</li>
</ul>
</li>
<li>
<a href="http://bioconductor.org/books/3.17/OSCA.multisample/" class="external-link">OSCA
multi-sample</a>
<ul>
<li>Chapter 4: <a href="http://bioconductor.org/books/3.17/OSCA.multisample/multi-sample-comparisons.html" class="external-link">DE
analyses between conditions</a>
</li>
</ul>
</li>
</ul>
</div>
<div class="section level2">
<h2 id="example-friction-of-spider-legs">Example: friction of spider legs<a class="anchor" aria-label="anchor" href="#example-friction-of-spider-legs"></a>
</h2>
<div class="columns-2">
<center>
<p><img src="images/srep01101-f4.jpg" height="600"></p>
</center>
<ul>
<li>
<strong>(A)</strong> Barplot showing total claw tuft area of the
corresponding legs.</li>
<li>
<strong>(B)</strong> Boxplot presenting friction coefficient data
illustrating median, interquartile range and extreme values.</li>
</ul>
</div>
<ul>
<li>Wolff &amp; Gorb, <a href="http://www.nature.com/articles/srep01101" class="external-link">Radial arrangement of
Janus-like setae permits friction control in spiders</a>, <em>Sci.
Rep.</em>
<ol start="2013" style="list-style-type: decimal"><li>
</li></ol>
</li>
</ul>
</div>
<div class="section level2">
<h2 id="questions">Questions<a class="anchor" aria-label="anchor" href="#questions"></a>
</h2>
<div class="columns-2">
<center>
<p><img src="images/srep01101-f4.jpg" height="600"></p>
</center>
<ul>
<li>Are the pulling and pushing friction coefficients different?</li>
<li>Are the friction coefficients different for the different leg
pairs?</li>
<li>Does the difference between pulling and pushing friction
coefficients vary by leg pair?</li>
</ul>
</div>
</div>
<div class="section level2">
<h2 id="qualitative-answers">Qualitative answers<a class="anchor" aria-label="anchor" href="#qualitative-answers"></a>
</h2>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/table.html" class="external-link">table</a></span><span class="op">(</span><span class="va">spider</span><span class="op">$</span><span class="va">leg</span>,<span class="va">spider</span><span class="op">$</span><span class="va">type</span><span class="op">)</span></span>
<span><span class="co">#&gt;     </span></span>
<span><span class="co">#&gt;      pull push</span></span>
<span><span class="co">#&gt;   L1   34   34</span></span>
<span><span class="co">#&gt;   L2   15   15</span></span>
<span><span class="co">#&gt;   L3   52   52</span></span>
<span><span class="co">#&gt;   L4   40   40</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">spider</span><span class="op">)</span></span>
<span><span class="co">#&gt;      leg                type              friction     </span></span>
<span><span class="co">#&gt;  Length:282         Length:282         Min.   :0.1700  </span></span>
<span><span class="co">#&gt;  Class :character   Class :character   1st Qu.:0.3900  </span></span>
<span><span class="co">#&gt;  Mode  :character   Mode  :character   Median :0.7600  </span></span>
<span><span class="co">#&gt;                                        Mean   :0.8217  </span></span>
<span><span class="co">#&gt;                                        3rd Qu.:1.2400  </span></span>
<span><span class="co">#&gt;                                        Max.   :1.8400</span></span></code></pre></div>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/boxplot.html" class="external-link">boxplot</a></span><span class="op">(</span><span class="va">spider</span><span class="op">$</span><span class="va">friction</span> <span class="op">~</span> <span class="va">spider</span><span class="op">$</span><span class="va">type</span> <span class="op">*</span> <span class="va">spider</span><span class="op">$</span><span class="va">leg</span>,</span>
<span>        col<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"grey90"</span>,<span class="st">"grey40"</span><span class="op">)</span>, las<span class="op">=</span><span class="fl">2</span>,</span>
<span>        main<span class="op">=</span><span class="st">"Friction coefficients of different leg pairs"</span><span class="op">)</span></span></code></pre></div>
<p><img src="day3_linearmodels_files/figure-html/unnamed-chunk-4-1.png" width="700" style="display: block; margin: auto;"></p>
<p>Notes:</p>
<ul>
<li>Pulling friction is higher</li>
<li>Pulling (but not pushing) friction increases for further back legs
(L1 -&gt; 4)</li>
<li>Variance isn’t constant</li>
</ul>
</div>
<div class="section level2">
<h2 id="what-are-linear-models">What are linear models?<a class="anchor" aria-label="anchor" href="#what-are-linear-models"></a>
</h2>
<p>The following are examples of linear models:</p>
<ol style="list-style-type: decimal">
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Y</mi><mi>i</mi></msub><mo>=</mo><msub><mi>β</mi><mn>0</mn></msub><mo>+</mo><msub><mi>β</mi><mn>1</mn></msub><msub><mi>x</mi><mi>i</mi></msub><mo>+</mo><msub><mi>ε</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">Y_i = \beta_0 + \beta_1 x_i + \varepsilon_i</annotation></semantics></math>
(simple linear regression)</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Y</mi><mi>i</mi></msub><mo>=</mo><msub><mi>β</mi><mn>0</mn></msub><mo>+</mo><msub><mi>β</mi><mn>1</mn></msub><msub><mi>x</mi><mi>i</mi></msub><mo>+</mo><msub><mi>β</mi><mn>2</mn></msub><msubsup><mi>x</mi><mi>i</mi><mn>2</mn></msubsup><mo>+</mo><msub><mi>ε</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">Y_i = \beta_0 + \beta_1 x_i + \beta_2 x_i^2 + \varepsilon_i</annotation></semantics></math>
(quadratic regression)</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Y</mi><mi>i</mi></msub><mo>=</mo><msub><mi>β</mi><mn>0</mn></msub><mo>+</mo><msub><mi>β</mi><mn>1</mn></msub><msub><mi>x</mi><mi>i</mi></msub><mo>+</mo><msub><mi>β</mi><mn>2</mn></msub><mo>×</mo><msup><mn>2</mn><msub><mi>x</mi><mi>i</mi></msub></msup><mo>+</mo><msub><mi>ε</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">Y_i = \beta_0 + \beta_1 x_i + \beta_2 \times 2^{x_i} + \varepsilon_i</annotation></semantics></math>
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mn>2</mn><msub><mi>x</mi><mi>i</mi></msub></msup><annotation encoding="application/x-tex">2^{x_i}</annotation></semantics></math>
is a new transformed variable)</li>
</ol>
</div>
<div class="section level2">
<h2 id="multiple-linear-regression-model">Multiple linear regression model<a class="anchor" aria-label="anchor" href="#multiple-linear-regression-model"></a>
</h2>
<ul>
<li>Linear models can have any number of predictors</li>
<li>Systematic part of model:</li>
</ul>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>y</mi><mo stretchy="false" form="prefix">|</mo><mi>x</mi><mo stretchy="true" form="postfix">]</mo></mrow><mo>=</mo><msub><mi>β</mi><mn>0</mn></msub><mo>+</mo><msub><mi>β</mi><mn>1</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>β</mi><mn>2</mn></msub><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>+</mo><msub><mi>β</mi><mi>p</mi></msub><msub><mi>x</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">
E[y|x] = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_p x_p
</annotation></semantics></math></p>
<ul>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>y</mi><mo stretchy="false" form="prefix">|</mo><mi>x</mi><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">E[y|x]</annotation></semantics></math>
is the expected value of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>
given
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>
</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>
is the outcome, response, or dependent variable</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>
is the vector of predictors / independent variables</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>p</mi></msub><annotation encoding="application/x-tex">x_p</annotation></semantics></math>
are the individual predictors or independent variables</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>β</mi><mi>p</mi></msub><annotation encoding="application/x-tex">\beta_p</annotation></semantics></math>
are the regression coefficients</li>
</ul>
<p>Random part of model:</p>
<p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>=</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">]</mo></mrow><mo>+</mo><msub><mi>ϵ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">y_i = E[y_i|x_i] + \epsilon_i</annotation></semantics></math></p>
<p>Assumptions of linear models:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ϵ</mi><mi>i</mi></msub><mover><mo>∼</mo><mrow><mi>i</mi><mi>i</mi><mi>d</mi></mrow></mover><mi>N</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo>,</mo><msubsup><mi>σ</mi><mi>ϵ</mi><mn>2</mn></msubsup><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\epsilon_i \stackrel{iid}{\sim} N(0, \sigma_\epsilon^2)</annotation></semantics></math></p>
<ul>
<li>Normal distribution</li>
<li>Mean zero at every value of predictors</li>
<li>Constant variance at every value of predictors</li>
<li>Values that are statistically independent</li>
</ul>
</div>
<div class="section level2">
<h2 id="continuous-predictors">Continuous predictors<a class="anchor" aria-label="anchor" href="#continuous-predictors"></a>
</h2>
<ul>
<li>
<strong>Coding:</strong> as-is, or may be scaled to unit variance
(which results in <em>adjusted</em> regression coefficients)</li>
<li>
<strong>Interpretation for linear regression:</strong> An increase
of one unit of the predictor results in this much difference in the
continuous outcome variable</li>
</ul>
</div>
<div class="section level2">
<h2 id="binary-predictors-2-levels">Binary predictors (2 levels)<a class="anchor" aria-label="anchor" href="#binary-predictors-2-levels"></a>
</h2>
<ul>
<li>
<strong>Coding:</strong> indicator or dummy variable (0-1
coding)</li>
<li>
<strong>Interpretation for linear regression:</strong> the increase
or decrease in average outcome levels in the group coded “1”, compared
to the reference category (“0”)
<ul>
<li>
<em>e.g.</em>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>y</mi><mo stretchy="false" form="prefix">|</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msub><mi>β</mi><mn>0</mn></msub><mo>+</mo><msub><mi>β</mi><mn>1</mn></msub><mi>x</mi></mrow><annotation encoding="application/x-tex">E(y|x) = \beta_0 + \beta_1 x</annotation></semantics></math>
</li>
<li>where x={ 1 if push friction, 0 if pull friction }</li>
</ul>
</li>
</ul>
</div>
<div class="section level2">
<h2 id="multilevel-categorical-predictors-ordinal-or-nominal">Multilevel categorical predictors (ordinal or nominal)<a class="anchor" aria-label="anchor" href="#multilevel-categorical-predictors-ordinal-or-nominal"></a>
</h2>
<ul>
<li>
<strong>Coding:</strong>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">K-1</annotation></semantics></math>
dummy variables for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math>-level
categorical variable</li>
<li>Comparisons with respect to a reference category, <em>e.g.</em>
<code>L1</code>:
<ul>
<li>
<code>L2</code>={1 if
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mn>2</mn><mrow><mi>n</mi><mi>d</mi></mrow></msup><annotation encoding="application/x-tex">2^{nd}</annotation></semantics></math>
leg pair, 0 otherwise},</li>
<li>
<code>L3</code>={1 if
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mn>3</mn><mrow><mi>n</mi><mi>d</mi></mrow></msup><annotation encoding="application/x-tex">3^{nd}</annotation></semantics></math>
leg pair, 0 otherwise},</li>
<li>
<code>L4</code>={1 if
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mn>4</mn><mrow><mi>t</mi><mi>h</mi></mrow></msup><annotation encoding="application/x-tex">4^{th}</annotation></semantics></math>
leg pair, 0 otherwise}.</li>
</ul>
</li>
<li>R re-codes factors to dummy variables automatically.</li>
<li>Dummy coding depends on the reference level</li>
</ul>
</div>
<div class="section level2">
<h2 id="model-formulae-in-r">Model formulae in R<a class="anchor" aria-label="anchor" href="#model-formulae-in-r"></a>
</h2>
<p><a href="http://ww2.coastal.edu/kingw/statistics/R-tutorials/formulae.html" class="external-link">Model
formulae tutorial</a></p>
<ul>
<li>regression functions in R such as <code><a href="https://rdrr.io/r/stats/aov.html" class="external-link">aov()</a></code>,
<code><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm()</a></code>, <code><a href="https://rdrr.io/r/stats/glm.html" class="external-link">glm()</a></code>, and <code>coxph()</code> use a
“model formula” interface.</li>
<li>The formula determines the model that will be built (and tested) by
the R procedure. The basic format is:</li>
</ul>
<p><code>&gt; response variable ~ explanatory variables</code></p>
<ul>
<li>The tilde means “is modeled by” or “is modeled as a function
of.”</li>
</ul>
</div>
<div class="section level2">
<h2 id="regression-with-a-single-predictor">Regression with a single predictor<a class="anchor" aria-label="anchor" href="#regression-with-a-single-predictor"></a>
</h2>
<p>Model formula for simple linear regression:</p>
<p><code>&gt; y ~ x</code></p>
<ul>
<li>where “x” is the explanatory (independent) variable</li>
<li>“y” is the response (dependent) variable.</li>
</ul>
</div>
<div class="section level2">
<h2 id="return-to-the-spider-legs">Return to the spider legs<a class="anchor" aria-label="anchor" href="#return-to-the-spider-legs"></a>
</h2>
<p>Friction coefficient for leg type of first leg pair:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">spider.sub</span> <span class="op">&lt;-</span> <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html" class="external-link">filter</a></span><span class="op">(</span><span class="va">spider</span>, <span class="va">leg</span><span class="op">==</span><span class="st">"L1"</span><span class="op">)</span></span>
<span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm</a></span><span class="op">(</span><span class="va">friction</span> <span class="op">~</span> <span class="va">type</span>, data<span class="op">=</span><span class="va">spider.sub</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; lm(formula = friction ~ type, data = spider.sub)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residuals:</span></span>
<span><span class="co">#&gt;      Min       1Q   Median       3Q      Max </span></span>
<span><span class="co">#&gt; -0.33147 -0.10735 -0.04941 -0.00147  0.76853 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span><span class="co">#&gt; (Intercept)  0.92147    0.03827  24.078  &lt; 2e-16 ***</span></span>
<span><span class="co">#&gt; typepush    -0.51412    0.05412  -9.499  5.7e-14 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residual standard error: 0.2232 on 66 degrees of freedom</span></span>
<span><span class="co">#&gt; Multiple R-squared:  0.5776, Adjusted R-squared:  0.5711 </span></span>
<span><span class="co">#&gt; F-statistic: 90.23 on 1 and 66 DF,  p-value: 5.698e-14</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="regression-on-spider-leg-type">Regression on spider leg type<a class="anchor" aria-label="anchor" href="#regression-on-spider-leg-type"></a>
</h2>
<p>Regression coefficients for <code>friction ~ type</code> for first
set of spider legs:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">broom</span><span class="fu">::</span><span class="fu"><a href="https://generics.r-lib.org/reference/tidy.html" class="external-link">tidy</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># A tibble: 2 × 5</span></span></span>
<span><span class="co">#&gt;   term        estimate std.error statistic  p.value</span></span>
<span><span class="co">#&gt;   <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>          <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>     <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>     <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>    <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">1</span> (Intercept)    0.921    0.038<span style="text-decoration: underline;">3</span>     24.1  2.12<span style="color: #949494;">e</span><span style="color: #BB0000;">-34</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">2</span> typepush      -<span style="color: #BB0000;">0.514</span>    0.054<span style="text-decoration: underline;">1</span>     -<span style="color: #BB0000;">9.50</span> 5.70<span style="color: #949494;">e</span><span style="color: #BB0000;">-14</span></span></span></code></pre></div>
<p>
</p>
<ul>
<li>How to interpret this table?
<ul>
<li>Coefficients for <strong>(Intercept)</strong> and
<strong>typepush</strong>
</li>
<li>Coefficients are t-distributed when assumptions are correct</li>
<li>Standard deviation in the estimates of each coefficient can be
calculated (standard errors)</li>
</ul>
</li>
</ul>
</div>
<div class="section level2">
<h2 id="interpretation-of-spider-leg-type-coefficients">Interpretation of spider leg type coefficients<a class="anchor" aria-label="anchor" href="#interpretation-of-spider-leg-type-coefficients"></a>
</h2>
<div class="figure">
<img src="day3_linearmodels_files/figure-html/spider_main_coef-1.png" alt="Diagram of the estimated coefficients in the linear model. The green arrow indicates the Intercept term, which goes from zero to the mean of the reference group (here the 'pull' samples). The orange arrow indicates the difference between the push group and the pull group, which is negative in this example. The circles show the individual samples, jittered horizontally to avoid overplotting." width="700"><p class="caption">
Diagram of the estimated coefficients in the linear model. The green
arrow indicates the Intercept term, which goes from zero to the mean of
the reference group (here the ‘pull’ samples). The orange arrow
indicates the difference between the push group and the pull group,
which is negative in this example. The circles show the individual
samples, jittered horizontally to avoid overplotting.
</p>
</div>
</div>
<div class="section level2">
<h2 id="regression-on-spider-leg-position">regression on spider leg <strong>position</strong><a class="anchor" aria-label="anchor" href="#regression-on-spider-leg-position"></a>
</h2>
<p>Remember there are positions 1-4</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm</a></span><span class="op">(</span><span class="va">friction</span> <span class="op">~</span> <span class="va">leg</span>, data<span class="op">=</span><span class="va">spider</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit.table</span> <span class="op">&lt;-</span> <span class="fu">xtable</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/xtable/man/xtable.html" class="external-link">xtable</a></span><span class="op">(</span><span class="va">fit</span>, label<span class="op">=</span><span class="cn">NULL</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">fit.table</span>, type<span class="op">=</span><span class="st">"html"</span><span class="op">)</span></span></code></pre></div>
<!-- html table generated in R 4.4.1 by xtable 1.8-4 package -->
<!-- Thu Jul 18 10:34:13 2024 -->
<table border="1" class="table">
<tr>
<th>
</th>
<th>
Estimate
</th>
<th>
Std. Error
</th>
<th>
t value
</th>
<th>
Pr(&gt;|t|)
</th>
</tr>
<tr>
<td align="right">
(Intercept)
</td>
<td align="right">
0.6644
</td>
<td align="right">
0.0538
</td>
<td align="right">
12.34
</td>
<td align="right">
0.0000
</td>
</tr>
<tr>
<td align="right">
legL2
</td>
<td align="right">
0.1719
</td>
<td align="right">
0.0973
</td>
<td align="right">
1.77
</td>
<td align="right">
0.0784
</td>
</tr>
<tr>
<td align="right">
legL3
</td>
<td align="right">
0.1605
</td>
<td align="right">
0.0693
</td>
<td align="right">
2.32
</td>
<td align="right">
0.0212
</td>
</tr>
<tr>
<td align="right">
legL4
</td>
<td align="right">
0.2813
</td>
<td align="right">
0.0732
</td>
<td align="right">
3.84
</td>
<td align="right">
0.0002
</td>
</tr>
</table>
<ul>
<li>Interpretation of the dummy variables legL2, legL3, legL4 ?</li>
</ul>
</div>
<div class="section level2">
<h2 id="regression-with-multiple-predictors">Regression with multiple predictors<a class="anchor" aria-label="anchor" href="#regression-with-multiple-predictors"></a>
</h2>
<p>Additional explanatory variables can be added as follows:</p>
<p><code>&gt; y ~ x + z</code></p>
<p>Note that “+” does not have its usual meaning, which would be
achieved by:</p>
<p><code>&gt; y ~ I(x + z)</code></p>
</div>
<div class="section level2">
<h2 id="regression-on-spider-leg-type-and-position">Regression on spider leg <strong>type</strong> and
<strong>position</strong><a class="anchor" aria-label="anchor" href="#regression-on-spider-leg-type-and-position"></a>
</h2>
<p>Remember there are positions 1-4</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm</a></span><span class="op">(</span><span class="va">friction</span> <span class="op">~</span> <span class="va">type</span> <span class="op">+</span> <span class="va">leg</span>, data<span class="op">=</span><span class="va">spider</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit.table</span> <span class="op">&lt;-</span> <span class="fu">xtable</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/xtable/man/xtable.html" class="external-link">xtable</a></span><span class="op">(</span><span class="va">fit</span>, label<span class="op">=</span><span class="cn">NULL</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">fit.table</span>, type<span class="op">=</span><span class="st">"html"</span><span class="op">)</span></span></code></pre></div>
<!-- html table generated in R 4.4.1 by xtable 1.8-4 package -->
<!-- Thu Jul 18 10:34:13 2024 -->
<table border="1" class="table">
<tr>
<th>
</th>
<th>
Estimate
</th>
<th>
Std. Error
</th>
<th>
t value
</th>
<th>
Pr(&gt;|t|)
</th>
</tr>
<tr>
<td align="right">
(Intercept)
</td>
<td align="right">
1.0539
</td>
<td align="right">
0.0282
</td>
<td align="right">
37.43
</td>
<td align="right">
0.0000
</td>
</tr>
<tr>
<td align="right">
typepush
</td>
<td align="right">
-0.7790
</td>
<td align="right">
0.0248
</td>
<td align="right">
-31.38
</td>
<td align="right">
0.0000
</td>
</tr>
<tr>
<td align="right">
legL2
</td>
<td align="right">
0.1719
</td>
<td align="right">
0.0457
</td>
<td align="right">
3.76
</td>
<td align="right">
0.0002
</td>
</tr>
<tr>
<td align="right">
legL3
</td>
<td align="right">
0.1605
</td>
<td align="right">
0.0325
</td>
<td align="right">
4.94
</td>
<td align="right">
0.0000
</td>
</tr>
<tr>
<td align="right">
legL4
</td>
<td align="right">
0.2813
</td>
<td align="right">
0.0344
</td>
<td align="right">
8.18
</td>
<td align="right">
0.0000
</td>
</tr>
</table>
<ul>
<li>this model still doesn’t represent how the friction differences
between different leg positions are modified by whether it is pulling or
pushing</li>
</ul>
</div>
<div class="section level2">
<h2 id="interaction-effect-modification">Interaction (effect modification)<a class="anchor" aria-label="anchor" href="#interaction-effect-modification"></a>
</h2>
<p>Interaction is modeled as the product of two covariates:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>y</mi><mo stretchy="false" form="prefix">|</mo><mi>x</mi><mo stretchy="true" form="postfix">]</mo></mrow><mo>=</mo><msub><mi>β</mi><mn>0</mn></msub><mo>+</mo><msub><mi>β</mi><mn>1</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>β</mi><mn>2</mn></msub><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><msub><mi>β</mi><mn>12</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>*</mo><msub><mi>x</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">
E[y|x] = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_{12} x_1*x_2
</annotation></semantics></math></p>
<div class="float">
<img src="images/coffee_interaction.jpg" alt="Interaction between coffee and time of day on performance"><div class="figcaption">Interaction between coffee and time of day on
performance</div>
</div>
<p>Image credit: <a href="http://personal.stevens.edu/~ysakamot/" class="external-link uri">http://personal.stevens.edu/~ysakamot/</a></p>
</div>
<div class="section level2">
<h2 id="model-formulae-contd">Model formulae (cont’d)<a class="anchor" aria-label="anchor" href="#model-formulae-contd"></a>
</h2>
<table class="table">
<colgroup>
<col width="26%">
<col width="26%">
<col width="47%">
</colgroup>
<thead><tr class="header">
<th>symbol</th>
<th>example</th>
<th>meaning</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>+</td>
<td>+ x</td>
<td>include this variable</td>
</tr>
<tr class="even">
<td>-</td>
<td>- x</td>
<td>delete this variable</td>
</tr>
<tr class="odd">
<td>:</td>
<td>x : z</td>
<td>include the interaction</td>
</tr>
<tr class="even">
<td>*</td>
<td>x * z</td>
<td>include these variables and their interactions</td>
</tr>
<tr class="odd">
<td>^</td>
<td>(u + v + w)^3</td>
<td>include these variables and all interactions up to three way</td>
</tr>
<tr class="even">
<td>1</td>
<td>-1</td>
<td>intercept: delete the intercept</td>
</tr>
</tbody>
</table>
<p>Note: order generally doesn’t matter (u+v OR v+u)</p>
</div>
<div class="section level2">
<h2 id="summary-types-of-standard-linear-models">Summary: types of standard linear models<a class="anchor" aria-label="anchor" href="#summary-types-of-standard-linear-models"></a>
</h2>
<pre><code><span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm</a></span><span class="op">(</span> <span class="va">y</span> <span class="op">~</span> <span class="va">u</span> <span class="op">+</span> <span class="va">v</span><span class="op">)</span></span></code></pre>
<p><code>u</code> and <code>v</code> factors:
<strong>ANOVA</strong><br><code>u</code> and <code>v</code> numeric: <strong>multiple
regression</strong><br>
one factor, one numeric: <strong>ANCOVA</strong></p>
<ul>
<li>R does a lot for you based on your variable classes
<ul>
<li>be <strong>sure</strong> you know the classes of your variables</li>
<li>be sure all rows of your regression output make sense</li>
</ul>
</li>
</ul>
</div>
<div class="section level2">
<h2 id="generalized-linear-models">Generalized Linear Models<a class="anchor" aria-label="anchor" href="#generalized-linear-models"></a>
</h2>
<ul>
<li>Linear regression is a special case of a broad family of models
called “Generalized Linear Models” (GLM)</li>
<li>This unifying approach allows to fit a large set of models using
maximum likelihood estimation methods (MLE) (Nelder &amp; Wedderburn,
1972)</li>
<li>Can model many types of data directly using appropriate
distributions, e.g. Poisson distribution for count data</li>
<li>Transformations of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>
not needed</li>
</ul>
</div>
<div class="section level2">
<h2 id="components-of-a-glm">Components of a GLM<a class="anchor" aria-label="anchor" href="#components-of-a-glm"></a>
</h2>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>y</mi><mo stretchy="false" form="prefix">|</mo><mi>x</mi><mo stretchy="true" form="postfix">]</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msub><mi>β</mi><mn>0</mn></msub><mo>+</mo><msub><mi>β</mi><mn>1</mn></msub><msub><mi>x</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub><mo>+</mo><msub><mi>β</mi><mn>2</mn></msub><msub><mi>x</mi><mrow><mn>2</mn><mi>i</mi></mrow></msub><mo>+</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>+</mo><msub><mi>β</mi><mi>p</mi></msub><msub><mi>x</mi><mrow><mi>p</mi><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">
g\left( E[y|x] \right) = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + ... + \beta_p x_{pi}
</annotation></semantics></math></p>
<ul>
<li>
<strong>Random component</strong> specifies the conditional
distribution for the response variable
<ul>
<li>doesn’t have to be normal</li>
<li>can be any distribution in the “exponential” family of
distributions</li>
</ul>
</li>
<li>
<strong>Systematic component</strong> specifies linear function of
predictors (linear predictor)</li>
<li>
<strong>Link</strong> [denoted by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>.</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">g(.)</annotation></semantics></math>]
specifies the relationship between the expected value of the random
component and the systematic component
<ul>
<li>can be linear or nonlinear</li>
</ul>
</li>
</ul>
</div>
<div class="section level2">
<h2 id="linear-regression-as-glm">Linear Regression as GLM<a class="anchor" aria-label="anchor" href="#linear-regression-as-glm"></a>
</h2>
<ul>
<li><p>Useful for log-transformed microarray data</p></li>
<li><p><strong>The model</strong>:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>=</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>y</mi><mo stretchy="false" form="prefix">|</mo><mi>x</mi><mo stretchy="true" form="postfix">]</mo></mrow><mo>+</mo><msub><mi>ϵ</mi><mi>i</mi></msub><mo>=</mo><msub><mi>β</mi><mn>0</mn></msub><mo>+</mo><msub><mi>β</mi><mn>1</mn></msub><msub><mi>x</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub><mo>+</mo><msub><mi>β</mi><mn>2</mn></msub><msub><mi>x</mi><mrow><mn>2</mn><mi>i</mi></mrow></msub><mo>+</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>+</mo><msub><mi>β</mi><mi>p</mi></msub><msub><mi>x</mi><mrow><mi>p</mi><mi>i</mi></mrow></msub><mo>+</mo><msub><mi>ϵ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">y_i = E[y|x] + \epsilon_i = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + ... + \beta_p x_{pi} + \epsilon_i</annotation></semantics></math></p></li>
<li><p><strong>Random component</strong> of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mi>i</mi></msub><annotation encoding="application/x-tex">y_i</annotation></semantics></math>
is normally distributed:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ϵ</mi><mi>i</mi></msub><mover><mo>∼</mo><mrow><mi>i</mi><mi>i</mi><mi>d</mi></mrow></mover><mi>N</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo>,</mo><msubsup><mi>σ</mi><mi>ϵ</mi><mn>2</mn></msubsup><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\epsilon_i \stackrel{iid}{\sim} N(0, \sigma_\epsilon^2)</annotation></semantics></math></p></li>
<li><p><strong>Systematic component</strong> (linear predictor):
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mn>0</mn></msub><mo>+</mo><msub><mi>β</mi><mn>1</mn></msub><msub><mi>x</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub><mo>+</mo><msub><mi>β</mi><mn>2</mn></msub><msub><mi>x</mi><mrow><mn>2</mn><mi>i</mi></mrow></msub><mo>+</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>+</mo><msub><mi>β</mi><mi>p</mi></msub><msub><mi>x</mi><mrow><mi>p</mi><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + ... + \beta_p x_{pi}</annotation></semantics></math></p></li>
<li><p><strong>Link function</strong> here is the <em>identity
link</em>:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>y</mi><mo stretchy="false" form="prefix">|</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>y</mi><mo stretchy="false" form="prefix">|</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">g(E(y | x)) = E(y | x)</annotation></semantics></math>.
We are modeling the mean directly, no transformation.</p></li>
</ul>
</div>
<div class="section level2">
<h2 id="logistic-regression-as-glm">Logistic Regression as GLM<a class="anchor" aria-label="anchor" href="#logistic-regression-as-glm"></a>
</h2>
<ul>
<li><p>Useful for binary outcomes, e.g. Single Nucleotide Polymorphisms
or somatic variants</p></li>
<li><p><strong>The model</strong>:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>o</mi><mi>g</mi><mi>i</mi><mi>t</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>l</mi><mi>o</mi><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><mfrac><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mn>1</mn><mo>−</mo><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msub><mi>β</mi><mn>0</mn></msub><mo>+</mo><msub><mi>β</mi><mn>1</mn></msub><msub><mi>x</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub><mo>+</mo><msub><mi>β</mi><mn>2</mn></msub><msub><mi>x</mi><mrow><mn>2</mn><mi>i</mi></mrow></msub><mo>+</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>+</mo><msub><mi>β</mi><mi>p</mi></msub><msub><mi>x</mi><mrow><mi>p</mi><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">
Logit(P(x)) = log \left( \frac{P(x)}{1-P(x)} \right) = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + ... + \beta_p x_{pi}
</annotation></semantics></math></p></li>
<li><p><strong>Random component</strong>:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mi>i</mi></msub><annotation encoding="application/x-tex">y_i</annotation></semantics></math>
follows a Binomial distribution (outcome is a binary variable)</p></li>
<li><p><strong>Systematic component</strong>: linear predictor
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mn>0</mn></msub><mo>+</mo><msub><mi>β</mi><mn>1</mn></msub><msub><mi>x</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub><mo>+</mo><msub><mi>β</mi><mn>2</mn></msub><msub><mi>x</mi><mrow><mn>2</mn><mi>i</mi></mrow></msub><mo>+</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>+</mo><msub><mi>β</mi><mi>p</mi></msub><msub><mi>x</mi><mrow><mi>p</mi><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">
\beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + ... + \beta_p x_{pi}
</annotation></semantics></math></p></li>
<li><p><strong>Link function</strong>: <em>logit</em> (log of the odds
that the event occurs)</p></li>
</ul>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>i</mi><mi>t</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>l</mi><mi>o</mi><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><mfrac><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mn>1</mn><mo>−</mo><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">
g(P(x)) = logit(P(x)) = log\left( \frac{P(x)}{1-P(x)} \right)
</annotation></semantics></math></p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msup><mi>g</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>β</mi><mn>0</mn></msub><mo>+</mo><msub><mi>β</mi><mn>1</mn></msub><msub><mi>x</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub><mo>+</mo><msub><mi>β</mi><mn>2</mn></msub><msub><mi>x</mi><mrow><mn>2</mn><mi>i</mi></mrow></msub><mo>+</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>+</mo><msub><mi>β</mi><mi>p</mi></msub><msub><mi>x</mi><mrow><mi>p</mi><mi>i</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">
P(x) = g^{-1}\left( \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + ... + \beta_p x_{pi}
 \right)
</annotation></semantics></math></p>
</div>
<div class="section level2">
<h2 id="log-linear-glm">Log-linear GLM<a class="anchor" aria-label="anchor" href="#log-linear-glm"></a>
</h2>
<p>The systematic part of the GLM is:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>y</mi><mo stretchy="false" form="prefix">|</mo><mi>x</mi><mo stretchy="true" form="postfix">]</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msub><mi>β</mi><mn>0</mn></msub><mo>+</mo><msub><mi>β</mi><mn>1</mn></msub><msub><mi>x</mi><mrow><mn>1</mn><mi>i</mi></mrow></msub><mo>+</mo><msub><mi>β</mi><mn>2</mn></msub><msub><mi>x</mi><mrow><mn>2</mn><mi>i</mi></mrow></msub><mo>+</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>+</mo><msub><mi>β</mi><mi>p</mi></msub><msub><mi>x</mi><mrow><mi>p</mi><mi>i</mi></mrow></msub><mo>+</mo><mi>l</mi><mi>o</mi><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>t</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">
log\left( E[y|x] \right) = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + ... + \beta_p x_{pi} + log(t_i)
</annotation></semantics></math></p>
<ul>
<li>Common for count data
<ul>
<li>can account for differences in sequencing depth by an
<em>offset</em>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>t</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">log(t_i)</annotation></semantics></math>
</li>
<li>guarantees non-negative expected number of counts</li>
<li>often used in conjunction with <strong>Poisson</strong> or
<strong>Negative Binomial</strong> error models</li>
</ul>
</li>
</ul>
</div>
<div class="section level2">
<h2 id="poisson-error-model">Poisson error model<a class="anchor" aria-label="anchor" href="#poisson-error-model"></a>
</h2>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>k</mi><mo>,</mo><mi>λ</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>λ</mi></mrow></msup><mfrac><msup><mi>λ</mi><mi>k</mi></msup><mrow><mi>k</mi><mi>!</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">
f(k, \lambda) = e^{-\lambda} \frac{\lambda^k}{k!}
</annotation></semantics></math></p>
<ul>
<li>where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math>
is the probability of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
events (e.g. # of reads counted), and</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>
is the mean number of events, so
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>y</mi><mo stretchy="false" form="prefix">|</mo><mi>x</mi><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">E[y|x]</annotation></semantics></math>
</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>
is also the variance of the number of events</li>
</ul>
</div>
<div class="section level2">
<h2 id="negative-binomial-error-model">Negative Binomial error model<a class="anchor" aria-label="anchor" href="#negative-binomial-error-model"></a>
</h2>
<ul>
<li>
<em>aka</em> gamma–Poisson mixture distribution</li>
</ul>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>k</mi><mo>,</mo><mi>λ</mi><mo>,</mo><mi>θ</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mfrac><mrow><mi>Γ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mfrac><mrow><mn>1</mn><mo>+</mo><mi>θ</mi><mi>k</mi></mrow><mi>θ</mi></mfrac><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mi>k</mi><mi>!</mi><mspace width="0.167em"></mspace><mi>Γ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mfrac><mn>1</mn><mi>θ</mi></mfrac><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><msup><mrow><mo stretchy="true" form="prefix">(</mo><mfrac><mrow><mi>θ</mi><mi>m</mi></mrow><mrow><mn>1</mn><mo>+</mo><mi>θ</mi><mi>m</mi></mrow></mfrac><mo stretchy="true" form="postfix">)</mo></mrow><mi>k</mi></msup><msup><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>+</mo><mi>θ</mi><mi>m</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>θ</mi></msup><mspace width="1.0em"></mspace><mrow><mtext mathvariant="normal">for </mtext><mspace width="0.333em"></mspace></mrow><mi>k</mi><mo>=</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mi>…</mi></mrow><annotation encoding="application/x-tex">
f(k, \lambda, \theta) = \frac{\Gamma(\frac{1 + \theta k}{\theta})}{k! \, \Gamma(\frac{1}{\theta})} 
    \left(\frac{\theta m}{1+\theta m}\right)^k 
    \left(1+\theta m\right)^\theta
    \quad\text{for }k = 0, 1, 2, \dotsc
</annotation></semantics></math></p>
<ul>
<li>where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi><annotation encoding="application/x-tex">f</annotation></semantics></math>
is still the probability of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
events (e.g. # of reads counted),</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>
is still the mean number of events, so
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>y</mi><mo stretchy="false" form="prefix">|</mo><mi>x</mi><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">E[y|x]</annotation></semantics></math>
</li>
<li>An additional <strong>dispersion parameter</strong>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>θ</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>
is estimated:
<ul>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi><mo>→</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\theta \rightarrow 0</annotation></semantics></math>:
Poisson distribution</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi><mo>→</mo><mi>∞</mi></mrow><annotation encoding="application/x-tex">\theta \rightarrow \infty</annotation></semantics></math>:
Gamma distribution</li>
</ul>
</li>
<li>The Poisson model can be considered as <strong>nested</strong>
within the Negative Binomial model</li>
<li>A likelihood ratio test comparing the two models is possible</li>
</ul>
</div>
<div class="section level2">
<h2 id="compare-poisson-vs--negative-binomial">Compare Poisson vs. Negative Binomial<a class="anchor" aria-label="anchor" href="#compare-poisson-vs--negative-binomial"></a>
</h2>
<ul>
<li>The Negative Binomial Distribution (<code><a href="https://rdrr.io/r/stats/Binomial.html" class="external-link">dbinom()</a></code>) has two
parameters:
<ol style="list-style-type: decimal">
<li># of trials n,</li>
<li>probability of success p</li>
</ol>
</li>
</ul>
<p><img src="day3_linearmodels_files/figure-html/unnamed-chunk-11-1.png" width="700"></p>
</div>
<div class="section level2">
<h2 id="additive-vs--multiplicative-models">Additive vs. multiplicative models<a class="anchor" aria-label="anchor" href="#additive-vs--multiplicative-models"></a>
</h2>
<ul>
<li>Linear regression is an <em>additive</em> model
<ul>
<li>
<em>e.g.</em> for two binary variables
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mn>1</mn></msub><mo>=</mo><mn>1.5</mn></mrow><annotation encoding="application/x-tex">\beta_1 = 1.5</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>β</mi><mn>2</mn></msub><mo>=</mo><mn>1.5</mn></mrow><annotation encoding="application/x-tex">\beta_2 = 1.5</annotation></semantics></math>.</li>
<li>If
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">x_1=1</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>2</mn></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">x_2=1</annotation></semantics></math>,
this adds 3.0 to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>y</mi><mo stretchy="false" form="prefix">|</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">E(y|x)</annotation></semantics></math>
</li>
</ul>
</li>
<li>Logistic and log-linear models are <em>multiplicative</em>:
<ul>
<li>If
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">x_1=1</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>2</mn></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">x_2=1</annotation></semantics></math>,
this adds 3.0 to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><mfrac><mi>P</mi><mrow><mn>1</mn><mo>−</mo><mi>P</mi></mrow></mfrac><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">log(\frac{P}{1-P})</annotation></semantics></math>
</li>
<li>Odds-ratio
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mfrac><mi>P</mi><mrow><mn>1</mn><mo>−</mo><mi>P</mi></mrow></mfrac><annotation encoding="application/x-tex">\frac{P}{1-P}</annotation></semantics></math>
increases 20-fold:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi><mi>x</mi><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>1.5</mn><mo>+</mo><mn>1.5</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">exp(1.5+1.5)</annotation></semantics></math>
or
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi><mi>x</mi><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>1.5</mn><mo stretchy="true" form="postfix">)</mo></mrow><mo>*</mo><mi>e</mi><mi>x</mi><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>1.5</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">exp(1.5) * exp(1.5)</annotation></semantics></math>
</li>
</ul>
</li>
</ul>
</div>
<div class="section level2">
<h2 id="inference-in-high-dimensions-many-variables">Inference in high dimensions (many variables)<a class="anchor" aria-label="anchor" href="#inference-in-high-dimensions-many-variables"></a>
</h2>
<ul>
<li>Conceptually similar to what we have already done
<ul>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Y</mi><mi>i</mi></msub><annotation encoding="application/x-tex">Y_i</annotation></semantics></math>
expression of a gene, etc</li>
</ul>
</li>
<li>Just repeated many times, e.g.:
<ul>
<li>is the mean expression of a gene different between two groups
(t-test)</li>
<li>is the mean expression of a gene different between any of several
groups (1-way ANOVA)</li>
<li>do this simple analysis thousands of times</li>
<li>
<em>note</em>: for small sample sizes, some Bayesian improvements
can be made (i.e. limma, edgeR, DESeq2)</li>
</ul>
</li>
<li>It is in prediction and machine learning where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi><annotation encoding="application/x-tex">Y</annotation></semantics></math>
is a label like patient outcome, and we can have high-dimensional
predictors</li>
</ul>
</div>
<div class="section level2">
<h2 id="multiple-testing">Multiple testing<a class="anchor" aria-label="anchor" href="#multiple-testing"></a>
</h2>
<ul>
<li>When testing thousands of true null hypotheses with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.05</mn></mrow><annotation encoding="application/x-tex">\alpha = 0.05</annotation></semantics></math>,
you expect a 5% type I error rate</li>
<li>What p-values are even smaller than you expect by chance from
multiple testing?</li>
<li>Two mainstream approaches for controlling type I error rate:</li>
</ul>
<ol style="list-style-type: decimal">
<li>Family-wise error rate (<em>e.g.</em>, Bonferroni correction).
<ul>
<li>Controlling FWER at 0.05 ensures that the probably of <em>any</em>
type I errors is &lt; 0.05.</li>
</ul>
</li>
<li>False Discovery Rate (<em>e.g.</em>, Benjamini-Hochberg correction)
<ul>
<li>Controlling FDR at 0.05 ensures that fraction of type I errors is
&lt; 0.05.</li>
<li>see <a href="https://www.huber.embl.de/msmb/06-chap.html" class="external-link">MSMB
Chapter 6 - testing</a>
</li>
</ul>
</li>
</ol>
</div>
<div class="section level2">
<h2 id="benjamini-hochberg-fdr-algorithm">Benjamini-Hochberg FDR algorithm<a class="anchor" aria-label="anchor" href="#benjamini-hochberg-fdr-algorithm"></a>
</h2>
<p>Source: <a href="https://www.huber.embl.de/msmb/06-chap.html#the-benjamini-hochberg-algorithm-for-controlling-the-fdr" class="external-link">MSMB
Chapter 6</a></p>
<ol style="list-style-type: decimal">
<li>order the p-values from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation></semantics></math>
hypothesis tests in increasing order,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mn>1</mn></msub><mo>,</mo><mi>…</mi><mo>,</mo><msub><mi>p</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">p_1, \ldots, p_m</annotation></semantics></math>
</li>
<li>for some choice of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ϕ</mi><annotation encoding="application/x-tex">\phi</annotation></semantics></math>
(our target FDR), find the largest value of that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
that satisfies:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>k</mi></msub><mo>≤</mo><mi>ϕ</mi><mi>k</mi><mi>/</mi><mi>m</mi></mrow><annotation encoding="application/x-tex">p_k \leq \phi k/m</annotation></semantics></math>
</li>
<li>reject the hypotheses
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">1, \ldots, k</annotation></semantics></math>
</li>
</ol>
<div class="figure" style="text-align: center">
<img src="images/fig-testing-awpvvisfdr-1.png" alt="Benjamini-Hochberg FDR, visually" width="49%" height="20%"><img src="images/fig-testing-BH-1.png" alt="Benjamini-Hochberg FDR, visually" width="49%" height="20%"><p class="caption">
Benjamini-Hochberg FDR, visually
</p>
</div>
<p>Important notes for intuition:</p>
<ul>
<li>You can have FDR &lt; 0.05 with thousands of tests even if your
smallest p-value is 0.01 or 0.001 (ie from permutation tests)</li>
<li>FDR is a property of groups of tests, not of individual tests</li>
<li>rank of FDR values can be different than rank of p-values</li>
</ul>
</div>
<div class="section level2">
<h2 id="fdr-alternatives-to-benjamini-hochberg">FDR alternatives to Benjamini-Hochberg<a class="anchor" aria-label="anchor" href="#fdr-alternatives-to-benjamini-hochberg"></a>
</h2>
<ul>
<li>
<a href="https://www.huber.embl.de/msmb/06-chap.html#sec-testing-localfdr" class="external-link">“Local”
False Discovery Rate</a> or <em>q-value</em>
<ul>
<li>The <em>q-value</em> of a test estimates the proportion of false
positives incurred when <em>that particular test and all smaller
p-values</em> are called significant (packages: <a href="https://bioconductor.org/packages/qvalue/" class="external-link">qvalue</a> or <a href="https://cran.r-project.org/web/packages/fdrtool/" class="external-link">fdrtool</a>)</li>
<li>q-value increases monotonically with p-value (unlike
Benjamini-Hochberg FDR)</li>
</ul>
</li>
<li>
<a href="https://www.huber.embl.de/msmb/06-chap.html#independent-hypothesis-weighting" class="external-link">Independent
Hypothesis Weighting</a>
<ul>
<li>can improve power by modeling the relationship between a covariate
property (such as mean expression) and probability of rejecting
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>H</mi><mn>0</mn></msub><annotation encoding="application/x-tex">H_0</annotation></semantics></math>
</li>
<li>works best with lots of tests (ie, thousands)</li>
<li>implemented in the <a href="https://bioconductor.org/packages/IHW/" class="external-link">IHW</a> Bioconductor
package and in <a href="https://bioconductor.org/packages/DESeq2/" class="external-link">DESeq2</a>
</li>
</ul>
</li>
</ul>
</div>
<div class="section level2">
<h2 id="beware-of-double-dipping-in-statistical-inference">Beware of “double-dipping” in statistical inference<a class="anchor" aria-label="anchor" href="#beware-of-double-dipping-in-statistical-inference"></a>
</h2>
<ol style="list-style-type: decimal">
<li>define a separation between observations</li>
<li>test for a difference across the separation</li>
</ol>
<div class="float">
<img src="images/doubledipping.jpg" alt="Example from: García-Mantrana et al., Gut Microbes 2020"><div class="figcaption">Example from: García-Mantrana <em>et al.</em>,
Gut Microbes 2020</div>
</div>
<ul>
<li>For a full treatment see <a href="https://arxiv.org/abs/2012.02936" class="external-link uri">https://arxiv.org/abs/2012.02936</a> and <a href="https://pubmed.ncbi.nlm.nih.gov/31521605" class="external-link uri">https://pubmed.ncbi.nlm.nih.gov/31521605</a>
</li>
<li>Or a nice lecture: Daniela Whitten “Double-dipping” in statistics:
<a href="https://youtu.be/tiv--XjPl9M" class="external-link uri">https://youtu.be/tiv--XjPl9M</a>
</li>
</ul>
</div>
<div class="section level2">
<h2 id="simple-example-of-double-dipping">Simple example of double-dipping<a class="anchor" aria-label="anchor" href="#simple-example-of-double-dipping"></a>
</h2>
<p><em>Step 1</em>: define an age classifier</p>
<ul>
<li>Elderly &gt;70 yrs</li>
<li>Youth &lt;18 years</li>
<li>Otherwise unclassified</li>
</ul>
<p><em>Step 2</em>: test for a difference in ages between elderly and
youth</p>
<p><strong>IMPORTANT</strong>: Even applying a fully-specified
classifier to a validation dataset does not protect against inflated
p-values from “double-dipping”</p>
</div>
<div class="section level2">
<h2 id="summary">Summary<a class="anchor" aria-label="anchor" href="#summary"></a>
</h2>
<ul>
<li><p>Linear models are the basis for identifying differential
expression / differential abundance</p></li>
<li>
<p><strong>Generalized Linear Models</strong> extend linear
regression to:</p>
<ul>
<li>binary
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>
(logistic regression)</li>
<li>count
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>
(log-linear regression with e.g. Poisson or Negative Binomial link
functions)</li>
</ul>
</li>
<li><p>FWER, FDR, local FDR (q-value), Independent Hypothesis
Testing</p></li>
<li><p>Be aware of “double-dipping” in statistical inference</p></li>
</ul>
</div>
<div class="section level2">
<h2 id="exercises">Exercises<a class="anchor" aria-label="anchor" href="#exercises"></a>
</h2>
<ul>
<li>Repeat analyses of OSCA multi-sample Chapter 4: <a href="http://bioconductor.org/books/3.17/OSCA.multisample/multi-sample-comparisons.html" class="external-link">DE
analyses between conditions</a>
</li>
</ul>
<p>Please discuss the following questions:</p>
<ol style="list-style-type: decimal">
<li>What is a major problem with the hypothesis testing in <a href="http://bioconductor.org/books/3.17/OSCA.multisample/multi-sample-comparisons.html#testing-for-between-label-differences" class="external-link">4.6
Testing for between-label differences</a>?
<ul>
<li>(note, the inference problem is acknowledged in this section)</li>
</ul>
</li>
<li>What is a related problem with the hypothesis testing in <a href="http://bioconductor.org/books/3.17/OSCA.multisample/multi-sample-comparisons.html#performing-the-de-analysis" class="external-link">4.4
Performing the DE analysis</a>?</li>
<li>How might you avoid these same problems, with the same data or a
multi’omic technology?</li>
</ol>
</div>
<div class="section level2">
<h2 id="links">Links<a class="anchor" aria-label="anchor" href="#links"></a>
</h2>
<ul>
<li>A built <a href="https://rpubs.com/lwaldron/AppStatBio2023_day3" class="external-link">html</a> version
of this lecture is available.</li>
<li>The <a href="https://github.com/waldronlab/AppStatBio" class="external-link">source</a> R
Markdown is available from Github.</li>
</ul>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Levi Waldron.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.0.</p>
</div>

    </footer>
</div>





  </body>
</html>
